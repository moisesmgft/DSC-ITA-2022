{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "from datetime import datetime\n",
    "import json\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(1970, 1, 1)\n",
    "end_date = datetime.now().date()\n",
    "tickers_path = 'data/tickers/sp500.json'\n",
    "dst_path = 'data/stocks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(tickers_path, dst_path, start_date=datetime(1970, 1, 1), end_date=datetime.now().date(), columns=['Close']):\n",
    "\n",
    "    assert 'Close' in columns\n",
    "\n",
    "    with open(tickers_path, 'r') as f:\n",
    "        tickers = json.load(f)\n",
    "\n",
    "    success = []\n",
    "    fail = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        \n",
    "        ticker = ticker.replace(\".\", \"-\")\n",
    "\n",
    "        try:\n",
    "            df = pdr.get_data_yahoo(symbols=ticker, start=start_date, end=end_date)\n",
    "\n",
    "            drop_list = list(set(df.columns) - set(columns))\n",
    "            df.drop(drop_list,axis=1,inplace=True)\n",
    "\n",
    "\n",
    "            download_path = dst_path + ticker + '.csv'\n",
    "            df.to_csv(download_path, index=True)\n",
    "\n",
    "            success.append(ticker)\n",
    "        except:\n",
    "            fail.append(ticker)\n",
    "\n",
    "    return success, fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv(src_path, dst_path, filename='dataset', how='outer'):\n",
    "    \n",
    "    files = [src_path + x for x in listdir(src_path) if 'csv' in x]\n",
    "\n",
    "    df1 = pd.read_csv(files[0], quoting=csv.QUOTE_NONE, error_bad_lines=False)\n",
    "    df1 = df1.rename({'Close': files[0].replace(src_path,'').replace('.csv','')}, axis=1)\n",
    "\n",
    "    for i in range(1,len(files)):\n",
    "        df2 = pd.read_csv(files[i], quoting=csv.QUOTE_NONE, error_bad_lines=False)\n",
    "        df2 = df2.rename({'Close': files[i].replace(src_path,'').replace('.csv','')}, axis=1)\n",
    "\n",
    "        df1 = pd.merge(df1, df2, how=how, on=['Date','Date']) \n",
    "\n",
    "    df1['Date'] = pd.to_datetime(df1['Date'])\n",
    "    df1 = df1.sort_values(by='Date')\n",
    "\n",
    "    df1 = df1.set_index('Date')\n",
    "    \n",
    "    df1.to_csv(dst_path + filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataa(dataset_path, data_size, input_tickers, output_tickers, step_size=0, input_size=60, output_size=20, feature_range=(0,1)):\n",
    "\n",
    "    if step_size==0:\n",
    "        step_size = input_size\n",
    "\n",
    "    df = pd.read_csv(dataset_path, quoting=csv.QUOTE_NONE, error_bad_lines=False)\n",
    "\n",
    "    predict_df = df[-input_size:]\n",
    "    df = df[-data_size-input_size:-input_size]\n",
    "    df = df.dropna(axis=1)\n",
    "\n",
    "    in_df = df.copy()\n",
    "    out_df = df.copy()\n",
    "\n",
    "    in_drop_list = list(set(df.columns) - set(input_tickers))\n",
    "    out_drop_list = list(set(df.columns) - set(output_tickers))\n",
    "\n",
    "    in_df.drop(in_drop_list,axis=1,inplace=True)\n",
    "    out_df.drop(out_drop_list,axis=1,inplace=True)\n",
    "    predict_df.drop(in_drop_list,axis=1,inplace=True)\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=feature_range)\n",
    "    in_dataset_scaled = scaler.fit_transform(in_df.values)\n",
    "    out_dataset_scaled = scaler.fit_transform(out_df.values)\n",
    "    x_predic = scaler.fit_transform(predict_df.values)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(input_size, in_dataset_scaled.shape[0]-output_size, step_size):\n",
    "        # adicionar passo\n",
    "        x.append(in_dataset_scaled[i-input_size:i,:])\n",
    "        y.append(out_dataset_scaled[i:i+output_size,:])\n",
    "\n",
    "    x, y = np.array(x), np.array(y)\n",
    "\n",
    "    output_tickers.sort()\n",
    "\n",
    "    dic = {ticker:[] for ticker in output_tickers}\n",
    "\n",
    "    return scaler, x, y, dic, x_predic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(x, y, train_ratio=0.7, validation_ratio=0.15, test_ratio=0.15):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1 - train_ratio)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tickers_in_range(df, day_range):\n",
    "\n",
    "    (min, max) = day_range\n",
    "    \n",
    "\n",
    "    df1 = df.copy()\n",
    "    df1 = df1[- (min - 1):].dropna(axis=1)\n",
    "    print(df1.shape)\n",
    "\n",
    "    if max == 'MAX':\n",
    "        return list(df1.columns)\n",
    "\n",
    "    df2 = df.copy()\n",
    "    df2 = df2[- (max - 1):].dropna(axis=1)\n",
    "    print(df2.shape)\n",
    "\n",
    "    tickers_list = list(set(df1.columns) - set(df2.columns))\n",
    "\n",
    "    return tickers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df.set_index('Date')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers1 = get_tickers_in_range(df, (188,360))\n",
    "tickers2 = get_tickers_in_range(df, (360,651))\n",
    "tickers3 = get_tickers_in_range(df, (651,1000))\n",
    "tickers4 = get_tickers_in_range(df, (1000,2000))\n",
    "tickers5 = get_tickers_in_range(df, (2000,5000))\n",
    "tickers6 = get_tickers_in_range(df, (5000,'MAX'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_dict(dic, arr, tickers):\n",
    "\n",
    "    d = dic.copy()\n",
    "\n",
    "    for i in range(arr.shape[1]):\n",
    "        ticker = tickers[i]\n",
    "        d[ticker] = arr[0,i,:]\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'A':0, 'B':0}\n",
    "tickers = ['A', 'B']\n",
    "real_close = np.array(\n",
    "    [\n",
    "        [\n",
    "            [1,1,1,1,1],\n",
    "            [2,2,2,2,2]\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "predict = np.array(\n",
    "    [\n",
    "        [\n",
    "            [2,2,2,2,2],\n",
    "            [3,3,3,3,3]\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "x = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [2, 3, 4, 5, 6],\n",
    "    [4, 9, 16, 25, 36],\n",
    "    [8, 27, 64, 123, 216]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_log(arr1, arr2):\n",
    "    return np.log(arr1) - np.log(arr2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import prod\n",
    "\n",
    "def to_return_log(arr, k, axis):\n",
    "    n = arr.shape[axis] - k \n",
    "    r = []\n",
    "\n",
    "    for i in range(n):\n",
    "        r.append(\n",
    "            return_log(np.take(arr, i+k, axis=axis), (np.take(arr, i, axis=axis)))\n",
    "        )\n",
    "\n",
    "    return np.array(r)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_return_log(x,3,axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
