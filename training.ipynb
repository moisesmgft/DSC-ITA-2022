{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 12:14:02.490216: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-22 12:14:02.600315: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-22 12:14:03.100708: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/moises/workspace/devel/lib\n",
      "2022-10-22 12:14:03.100764: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/moises/workspace/devel/lib\n",
      "2022-10-22 12:14:03.100770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 12:14:03.614103: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-22 12:14:03.653785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 12:14:03.673867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 12:14:03.674036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 12:14:04.042559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 12:14:04.042752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 12:14:04.042877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 12:14:04.042973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4005 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-10-22 12:14:04.044366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 12:14:04.044516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 12:14:04.044668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 12:14:04.044938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 12:14:04.045133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 12:14:04.045256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 12:14:04.045435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 12:14:04.045744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-22 12:14:04.045820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4005 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "K._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_sets_path = 'data/tickers/sets/'\n",
    "\n",
    "sets_files = sorted([tickers_sets_path + x for x in listdir(tickers_sets_path) if 'json' in x], reverse=True)\n",
    "\n",
    "tickers_sets = []\n",
    "\n",
    "for set_file in sets_files:\n",
    "    with open(set_file, 'r') as f:\n",
    "        tickers_sets.append(json.load(f))\n",
    "\n",
    "dst_path = 'data/stocks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset.csv')\n",
    "df = df.set_index('Date')\n",
    "df = df[:-80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 4800\n",
    "input_tickers = tickers_sets[0]\n",
    "output_tickers = tickers_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "394 394\n",
      "394 394\n"
     ]
    }
   ],
   "source": [
    "scaler, x, y, dic = dataa(df, data_size, input_tickers, output_tickers, step_size=1, input_size=60, output_size=20, feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = train_val_test_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (x.shape[1],x.shape[2])\n",
    "output_shape = (y.shape[1], y.shape[2])\n",
    "layers_info_list = [\n",
    "    [\n",
    "        (50, 0.2, True), \n",
    "        (70, 0.2, True),\n",
    "        (70, 0.2, True),\n",
    "        (60, 0.2, True),\n",
    "        (40, 0.2, False)\n",
    "    ],\n",
    "    [\n",
    "        (100, 0.2, True), \n",
    "        (100, 0.2, True),\n",
    "        (100, 0.2, True),\n",
    "        (150, 0.2, False)\n",
    "    ],\n",
    "    [\n",
    "        (450, 0.2, True), \n",
    "        (600, 0.2, True),\n",
    "        (600, 0.2, True),\n",
    "        (400, 0.2, False)\n",
    "    ],\n",
    "    [\n",
    "        (50, 0.2, True), \n",
    "        (50, 0.2, True),\n",
    "        (50, 0.2, True),\n",
    "        (50, 0.2, True),\n",
    "        (50, 0.2, True),\n",
    "        (50, 0.2, True),\n",
    "        (50, 0.2, True),\n",
    "        (50, 0.2, True),\n",
    "        (50, 0.2, True),\n",
    "        (50, 0.2, True),\n",
    "        (50, 0.2, True),\n",
    "        (50, 0.2, True),\n",
    "        (50, 0.2, True),\n",
    "        (50, 0.2, False)\n",
    "    ],\n",
    "    [\n",
    "        (85, 0.2, True), \n",
    "        (85, 0.2, True),\n",
    "        (85, 0.2, True),\n",
    "        (85, 0.2, True),\n",
    "        (85, 0.2, True),\n",
    "        (85, 0.2, True),\n",
    "        (85, 0.2, True),\n",
    "        (85, 0.2, True),\n",
    "        (85, 0.2, False)\n",
    "    ]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    [\n",
    "        (600, 0.2, True), \n",
    "        (800, 0.2, True),\n",
    "        (800, 0.2, True),\n",
    "        (600, 0.2, False)\n",
    "    ],\"\"\"\n",
    "\n",
    "layers_info_list = [\n",
    "    [\n",
    "        (1000, 0.15, True), \n",
    "        (1000, 0.15, True),\n",
    "        (1000, 0.15, False)\n",
    "    ],\n",
    "    [\n",
    "        (800, 0.1, True), \n",
    "        (1000, 0.1, True),\n",
    "        (1000, 0.1, True),\n",
    "        (800, 0.1, False)\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for layers_info in layers_info_list:\n",
    "\n",
    "    models.append(create_model(input_shape, output_shape, layers_info, metrics=['accuracy', 'mse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 12:14:13.498174: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 15s 115ms/step - loss: 0.1115 - accuracy: 0.0880 - mse: 0.0192 - val_loss: 0.0722 - val_accuracy: 0.2275 - val_mse: 0.0058\n",
      "Epoch 2/100\n",
      "104/104 [==============================] - 11s 108ms/step - loss: 0.0626 - accuracy: 0.2323 - mse: 0.0045 - val_loss: 0.0572 - val_accuracy: 0.2798 - val_mse: 0.0036\n",
      "Epoch 3/100\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.0529 - accuracy: 0.2794 - mse: 0.0031 - val_loss: 0.0476 - val_accuracy: 0.3066 - val_mse: 0.0025\n",
      "Epoch 4/100\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.0470 - accuracy: 0.3134 - mse: 0.0025 - val_loss: 0.0471 - val_accuracy: 0.2970 - val_mse: 0.0025\n",
      "Epoch 5/100\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.0447 - accuracy: 0.3261 - mse: 0.0022 - val_loss: 0.0454 - val_accuracy: 0.3318 - val_mse: 0.0024\n",
      "Epoch 6/100\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.0458 - accuracy: 0.3380 - mse: 0.0024 - val_loss: 0.0396 - val_accuracy: 0.3696 - val_mse: 0.0018\n",
      "Epoch 7/100\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.0413 - accuracy: 0.3567 - mse: 0.0019 - val_loss: 0.0352 - val_accuracy: 0.3587 - val_mse: 0.0014\n",
      "Epoch 8/100\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.0401 - accuracy: 0.3736 - mse: 0.0018 - val_loss: 0.0371 - val_accuracy: 0.3917 - val_mse: 0.0016\n",
      "Epoch 9/100\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.0392 - accuracy: 0.3823 - mse: 0.0017 - val_loss: 0.0354 - val_accuracy: 0.3922 - val_mse: 0.0014\n",
      "Epoch 10/100\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.0368 - accuracy: 0.3967 - mse: 0.0015 - val_loss: 0.0331 - val_accuracy: 0.4136 - val_mse: 0.0012\n",
      "Epoch 11/100\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.0365 - accuracy: 0.4059 - mse: 0.0015 - val_loss: 0.0346 - val_accuracy: 0.4175 - val_mse: 0.0013\n",
      "Epoch 12/100\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.0361 - accuracy: 0.4181 - mse: 0.0015 - val_loss: 0.0318 - val_accuracy: 0.4190 - val_mse: 0.0011\n",
      "Epoch 13/100\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.0369 - accuracy: 0.4005 - mse: 0.0015 - val_loss: 0.0368 - val_accuracy: 0.4204 - val_mse: 0.0015\n",
      "Epoch 14/100\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.0366 - accuracy: 0.4073 - mse: 0.0015 - val_loss: 0.0361 - val_accuracy: 0.4303 - val_mse: 0.0014\n",
      "Epoch 15/100\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.0353 - accuracy: 0.4190 - mse: 0.0014 - val_loss: 0.0323 - val_accuracy: 0.4532 - val_mse: 0.0011\n",
      "Epoch 16/100\n",
      "104/104 [==============================] - 11s 110ms/step - loss: 0.0338 - accuracy: 0.4319 - mse: 0.0013 - val_loss: 0.0357 - val_accuracy: 0.4186 - val_mse: 0.0014\n",
      "Epoch 17/100\n",
      "104/104 [==============================] - 11s 110ms/step - loss: 0.0336 - accuracy: 0.4290 - mse: 0.0013 - val_loss: 0.0314 - val_accuracy: 0.4290 - val_mse: 0.0011\n",
      "Epoch 18/100\n",
      "104/104 [==============================] - 11s 110ms/step - loss: 0.0332 - accuracy: 0.4329 - mse: 0.0012 - val_loss: 0.0310 - val_accuracy: 0.4625 - val_mse: 0.0011\n",
      "Epoch 19/100\n",
      "104/104 [==============================] - 11s 110ms/step - loss: 0.0322 - accuracy: 0.4459 - mse: 0.0012 - val_loss: 0.0303 - val_accuracy: 0.4601 - val_mse: 0.0010\n",
      "Epoch 20/100\n",
      "104/104 [==============================] - 11s 110ms/step - loss: 0.0317 - accuracy: 0.4445 - mse: 0.0011 - val_loss: 0.0296 - val_accuracy: 0.4835 - val_mse: 9.6606e-04\n",
      "Epoch 21/100\n",
      "104/104 [==============================] - 11s 110ms/step - loss: 0.0304 - accuracy: 0.4540 - mse: 0.0010 - val_loss: 0.0278 - val_accuracy: 0.4778 - val_mse: 8.5185e-04\n",
      "Epoch 22/100\n",
      "104/104 [==============================] - 11s 110ms/step - loss: 0.0308 - accuracy: 0.4579 - mse: 0.0011 - val_loss: 0.0253 - val_accuracy: 0.4683 - val_mse: 7.2329e-04\n",
      "Epoch 23/100\n",
      "104/104 [==============================] - 11s 110ms/step - loss: 0.0301 - accuracy: 0.4554 - mse: 0.0010 - val_loss: 0.0276 - val_accuracy: 0.4435 - val_mse: 8.5228e-04\n",
      "Epoch 24/100\n",
      "104/104 [==============================] - 11s 110ms/step - loss: 0.0295 - accuracy: 0.4630 - mse: 9.7066e-04 - val_loss: 0.0246 - val_accuracy: 0.4746 - val_mse: 6.7484e-04\n",
      "Epoch 25/100\n",
      "104/104 [==============================] - 11s 110ms/step - loss: 0.0291 - accuracy: 0.4727 - mse: 9.4448e-04 - val_loss: 0.0265 - val_accuracy: 0.4910 - val_mse: 7.8486e-04\n",
      "Epoch 26/100\n",
      "104/104 [==============================] - 12s 111ms/step - loss: 0.0292 - accuracy: 0.4800 - mse: 9.4902e-04 - val_loss: 0.0267 - val_accuracy: 0.4665 - val_mse: 7.9581e-04\n",
      "Epoch 27/100\n",
      "104/104 [==============================] - 11s 111ms/step - loss: 0.0280 - accuracy: 0.4899 - mse: 8.7579e-04 - val_loss: 0.0261 - val_accuracy: 0.4809 - val_mse: 7.4890e-04\n",
      "Epoch 28/100\n",
      "104/104 [==============================] - 12s 111ms/step - loss: 0.0282 - accuracy: 0.4878 - mse: 8.9577e-04 - val_loss: 0.0236 - val_accuracy: 0.5109 - val_mse: 6.2516e-04\n",
      "Epoch 29/100\n",
      "104/104 [==============================] - 12s 111ms/step - loss: 0.0280 - accuracy: 0.4835 - mse: 8.6738e-04 - val_loss: 0.0263 - val_accuracy: 0.5075 - val_mse: 7.6273e-04\n",
      "Epoch 30/100\n",
      "104/104 [==============================] - 12s 112ms/step - loss: 0.0278 - accuracy: 0.4942 - mse: 8.5817e-04 - val_loss: 0.0252 - val_accuracy: 0.4830 - val_mse: 7.3628e-04\n",
      "Epoch 31/100\n",
      "104/104 [==============================] - 12s 111ms/step - loss: 0.0282 - accuracy: 0.4888 - mse: 8.9738e-04 - val_loss: 0.0239 - val_accuracy: 0.5108 - val_mse: 6.3796e-04\n",
      "Epoch 32/100\n",
      "104/104 [==============================] - 12s 112ms/step - loss: 0.0282 - accuracy: 0.4803 - mse: 9.1224e-04 - val_loss: 0.0318 - val_accuracy: 0.4736 - val_mse: 0.0012\n",
      "Epoch 33/100\n",
      "104/104 [==============================] - 12s 112ms/step - loss: 0.0280 - accuracy: 0.4885 - mse: 8.9095e-04 - val_loss: 0.0249 - val_accuracy: 0.4956 - val_mse: 6.9310e-04\n",
      "Epoch 34/100\n",
      "104/104 [==============================] - 12s 112ms/step - loss: 0.0273 - accuracy: 0.5008 - mse: 8.3833e-04 - val_loss: 0.0231 - val_accuracy: 0.5189 - val_mse: 6.0065e-04\n",
      "Epoch 35/100\n",
      "104/104 [==============================] - 12s 112ms/step - loss: 0.0263 - accuracy: 0.5071 - mse: 7.7350e-04 - val_loss: 0.0233 - val_accuracy: 0.5145 - val_mse: 5.9985e-04\n",
      "Epoch 36/100\n",
      "104/104 [==============================] - 12s 112ms/step - loss: 0.0265 - accuracy: 0.5098 - mse: 7.7964e-04 - val_loss: 0.0233 - val_accuracy: 0.5382 - val_mse: 6.0168e-04\n",
      "Epoch 37/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0259 - accuracy: 0.5174 - mse: 7.5009e-04 - val_loss: 0.0223 - val_accuracy: 0.5403 - val_mse: 5.5511e-04\n",
      "Epoch 38/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0260 - accuracy: 0.5120 - mse: 7.4896e-04 - val_loss: 0.0215 - val_accuracy: 0.5306 - val_mse: 5.1882e-04\n",
      "Epoch 39/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0251 - accuracy: 0.5190 - mse: 7.0639e-04 - val_loss: 0.0228 - val_accuracy: 0.5273 - val_mse: 5.7357e-04\n",
      "Epoch 40/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0260 - accuracy: 0.5171 - mse: 7.5336e-04 - val_loss: 0.0211 - val_accuracy: 0.5251 - val_mse: 4.9551e-04\n",
      "Epoch 41/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0259 - accuracy: 0.5163 - mse: 7.5517e-04 - val_loss: 0.0213 - val_accuracy: 0.5315 - val_mse: 5.1276e-04\n",
      "Epoch 42/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0250 - accuracy: 0.5210 - mse: 6.9528e-04 - val_loss: 0.0219 - val_accuracy: 0.5368 - val_mse: 5.3888e-04\n",
      "Epoch 43/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0247 - accuracy: 0.5284 - mse: 6.7829e-04 - val_loss: 0.0207 - val_accuracy: 0.5576 - val_mse: 4.7819e-04\n",
      "Epoch 44/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0247 - accuracy: 0.5344 - mse: 6.7874e-04 - val_loss: 0.0216 - val_accuracy: 0.5556 - val_mse: 5.1552e-04\n",
      "Epoch 45/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0262 - accuracy: 0.5174 - mse: 7.7115e-04 - val_loss: 0.0209 - val_accuracy: 0.5698 - val_mse: 4.8617e-04\n",
      "Epoch 46/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0250 - accuracy: 0.5347 - mse: 6.9510e-04 - val_loss: 0.0220 - val_accuracy: 0.5593 - val_mse: 5.3705e-04\n",
      "Epoch 47/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0268 - accuracy: 0.4962 - mse: 8.2219e-04 - val_loss: 0.0265 - val_accuracy: 0.5201 - val_mse: 7.9018e-04\n",
      "Epoch 48/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0255 - accuracy: 0.5187 - mse: 7.3109e-04 - val_loss: 0.0209 - val_accuracy: 0.5496 - val_mse: 4.8848e-04\n",
      "Epoch 49/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0242 - accuracy: 0.5371 - mse: 6.5341e-04 - val_loss: 0.0202 - val_accuracy: 0.5530 - val_mse: 4.5393e-04\n",
      "Epoch 50/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0235 - accuracy: 0.5398 - mse: 6.1363e-04 - val_loss: 0.0201 - val_accuracy: 0.5469 - val_mse: 4.5656e-04\n",
      "Epoch 51/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0248 - accuracy: 0.5356 - mse: 6.9262e-04 - val_loss: 0.0218 - val_accuracy: 0.5636 - val_mse: 5.2343e-04\n",
      "Epoch 52/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0252 - accuracy: 0.5257 - mse: 7.1692e-04 - val_loss: 0.0198 - val_accuracy: 0.5735 - val_mse: 4.3808e-04\n",
      "Epoch 53/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0250 - accuracy: 0.5359 - mse: 7.0216e-04 - val_loss: 0.0201 - val_accuracy: 0.5637 - val_mse: 4.5176e-04\n",
      "Epoch 54/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0237 - accuracy: 0.5467 - mse: 6.2532e-04 - val_loss: 0.0198 - val_accuracy: 0.5735 - val_mse: 4.3517e-04\n",
      "Epoch 55/100\n",
      "104/104 [==============================] - 12s 112ms/step - loss: 0.0232 - accuracy: 0.5572 - mse: 6.0230e-04 - val_loss: 0.0199 - val_accuracy: 0.5835 - val_mse: 4.3812e-04\n",
      "Epoch 56/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0228 - accuracy: 0.5490 - mse: 5.7942e-04 - val_loss: 0.0196 - val_accuracy: 0.5785 - val_mse: 4.2782e-04\n",
      "Epoch 57/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0233 - accuracy: 0.5563 - mse: 6.0256e-04 - val_loss: 0.0195 - val_accuracy: 0.5751 - val_mse: 4.2124e-04\n",
      "Epoch 58/100\n",
      "104/104 [==============================] - 12s 112ms/step - loss: 0.0233 - accuracy: 0.5490 - mse: 6.0483e-04 - val_loss: 0.0190 - val_accuracy: 0.5826 - val_mse: 4.0635e-04\n",
      "Epoch 59/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0223 - accuracy: 0.5595 - mse: 5.5199e-04 - val_loss: 0.0187 - val_accuracy: 0.5685 - val_mse: 3.9504e-04\n",
      "Epoch 60/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0230 - accuracy: 0.5540 - mse: 5.9427e-04 - val_loss: 0.0209 - val_accuracy: 0.5774 - val_mse: 4.8575e-04\n",
      "Epoch 61/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0228 - accuracy: 0.5552 - mse: 5.7870e-04 - val_loss: 0.0213 - val_accuracy: 0.5495 - val_mse: 5.0011e-04\n",
      "Epoch 62/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0232 - accuracy: 0.5529 - mse: 6.0017e-04 - val_loss: 0.0184 - val_accuracy: 0.5994 - val_mse: 3.7665e-04\n",
      "Epoch 63/100\n",
      "104/104 [==============================] - 12s 112ms/step - loss: 0.0221 - accuracy: 0.5680 - mse: 5.4400e-04 - val_loss: 0.0186 - val_accuracy: 0.5857 - val_mse: 3.7976e-04\n",
      "Epoch 64/100\n",
      "104/104 [==============================] - 12s 112ms/step - loss: 0.0219 - accuracy: 0.5662 - mse: 5.3293e-04 - val_loss: 0.0181 - val_accuracy: 0.5965 - val_mse: 3.6862e-04\n",
      "Epoch 65/100\n",
      "104/104 [==============================] - 11s 110ms/step - loss: 0.0220 - accuracy: 0.5666 - mse: 5.3876e-04 - val_loss: 0.0198 - val_accuracy: 0.5809 - val_mse: 4.3561e-04\n",
      "Epoch 66/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0230 - accuracy: 0.5521 - mse: 5.8881e-04 - val_loss: 0.0187 - val_accuracy: 0.5805 - val_mse: 3.8631e-04\n",
      "Epoch 67/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0221 - accuracy: 0.5653 - mse: 5.4463e-04 - val_loss: 0.0198 - val_accuracy: 0.5872 - val_mse: 4.3712e-04\n",
      "Epoch 68/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0217 - accuracy: 0.5690 - mse: 5.2501e-04 - val_loss: 0.0180 - val_accuracy: 0.5822 - val_mse: 3.6246e-04\n",
      "Epoch 69/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0214 - accuracy: 0.5763 - mse: 5.0810e-04 - val_loss: 0.0181 - val_accuracy: 0.5839 - val_mse: 3.6356e-04\n",
      "Epoch 70/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0217 - accuracy: 0.5660 - mse: 5.2918e-04 - val_loss: 0.0173 - val_accuracy: 0.5895 - val_mse: 3.3507e-04\n",
      "Epoch 71/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0215 - accuracy: 0.5766 - mse: 5.1234e-04 - val_loss: 0.0178 - val_accuracy: 0.5882 - val_mse: 3.5613e-04\n",
      "Epoch 72/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0218 - accuracy: 0.5629 - mse: 5.3151e-04 - val_loss: 0.0187 - val_accuracy: 0.5927 - val_mse: 3.8798e-04\n",
      "Epoch 73/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0215 - accuracy: 0.5707 - mse: 5.1382e-04 - val_loss: 0.0174 - val_accuracy: 0.5896 - val_mse: 3.4006e-04\n",
      "Epoch 74/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0225 - accuracy: 0.5652 - mse: 5.7711e-04 - val_loss: 0.0177 - val_accuracy: 0.5931 - val_mse: 3.5031e-04\n",
      "Epoch 75/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0218 - accuracy: 0.5730 - mse: 5.2935e-04 - val_loss: 0.0182 - val_accuracy: 0.5974 - val_mse: 3.6881e-04\n",
      "Epoch 76/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0212 - accuracy: 0.5750 - mse: 5.0155e-04 - val_loss: 0.0176 - val_accuracy: 0.5906 - val_mse: 3.4747e-04\n",
      "Epoch 77/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0210 - accuracy: 0.5781 - mse: 4.9169e-04 - val_loss: 0.0172 - val_accuracy: 0.6004 - val_mse: 3.3356e-04\n",
      "Epoch 78/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0208 - accuracy: 0.5815 - mse: 4.8069e-04 - val_loss: 0.0180 - val_accuracy: 0.6018 - val_mse: 3.5571e-04\n",
      "Epoch 79/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0210 - accuracy: 0.5817 - mse: 4.9289e-04 - val_loss: 0.0176 - val_accuracy: 0.6004 - val_mse: 3.4567e-04\n",
      "Epoch 80/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0212 - accuracy: 0.5737 - mse: 5.0348e-04 - val_loss: 0.0200 - val_accuracy: 0.5864 - val_mse: 4.4810e-04\n",
      "Epoch 81/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0212 - accuracy: 0.5747 - mse: 5.0351e-04 - val_loss: 0.0176 - val_accuracy: 0.5979 - val_mse: 3.4663e-04\n",
      "Epoch 82/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0206 - accuracy: 0.5831 - mse: 4.7099e-04 - val_loss: 0.0171 - val_accuracy: 0.6186 - val_mse: 3.3152e-04\n",
      "Epoch 83/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0208 - accuracy: 0.5849 - mse: 4.8538e-04 - val_loss: 0.0177 - val_accuracy: 0.5804 - val_mse: 3.4937e-04\n",
      "Epoch 84/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0208 - accuracy: 0.5761 - mse: 4.8373e-04 - val_loss: 0.0174 - val_accuracy: 0.6031 - val_mse: 3.3872e-04\n",
      "Epoch 85/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.0209 - accuracy: 0.5715 - mse: 4.9080e-04 - val_loss: 0.0176 - val_accuracy: 0.5975 - val_mse: 3.4664e-04\n",
      "Epoch 86/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0206 - accuracy: 0.5853 - mse: 4.7330e-04 - val_loss: 0.0171 - val_accuracy: 0.5990 - val_mse: 3.2774e-04\n",
      "Epoch 87/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0207 - accuracy: 0.5848 - mse: 4.7600e-04 - val_loss: 0.0165 - val_accuracy: 0.6102 - val_mse: 3.0765e-04\n",
      "Epoch 88/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0202 - accuracy: 0.5908 - mse: 4.5621e-04 - val_loss: 0.0165 - val_accuracy: 0.6121 - val_mse: 3.0559e-04\n",
      "Epoch 89/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0199 - accuracy: 0.5879 - mse: 4.4288e-04 - val_loss: 0.0170 - val_accuracy: 0.6125 - val_mse: 3.2044e-04\n",
      "Epoch 90/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0203 - accuracy: 0.5901 - mse: 4.5805e-04 - val_loss: 0.0166 - val_accuracy: 0.6118 - val_mse: 3.0922e-04\n",
      "Epoch 91/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0210 - accuracy: 0.5833 - mse: 4.9126e-04 - val_loss: 0.0210 - val_accuracy: 0.5953 - val_mse: 4.9654e-04\n",
      "Epoch 92/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0218 - accuracy: 0.5750 - mse: 5.3666e-04 - val_loss: 0.0180 - val_accuracy: 0.6078 - val_mse: 3.5865e-04\n",
      "Epoch 93/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0201 - accuracy: 0.5868 - mse: 4.4981e-04 - val_loss: 0.0168 - val_accuracy: 0.6198 - val_mse: 3.1350e-04\n",
      "Epoch 94/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0204 - accuracy: 0.5871 - mse: 4.6402e-04 - val_loss: 0.0176 - val_accuracy: 0.6035 - val_mse: 3.4940e-04\n",
      "Epoch 95/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0202 - accuracy: 0.5884 - mse: 4.5585e-04 - val_loss: 0.0177 - val_accuracy: 0.6206 - val_mse: 3.4265e-04\n",
      "Epoch 96/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0199 - accuracy: 0.5956 - mse: 4.3822e-04 - val_loss: 0.0174 - val_accuracy: 0.6081 - val_mse: 3.3722e-04\n",
      "Epoch 97/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0204 - accuracy: 0.5854 - mse: 4.6283e-04 - val_loss: 0.0168 - val_accuracy: 0.6150 - val_mse: 3.1777e-04\n",
      "Epoch 98/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0198 - accuracy: 0.5891 - mse: 4.3738e-04 - val_loss: 0.0175 - val_accuracy: 0.6042 - val_mse: 3.4123e-04\n",
      "Epoch 99/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0197 - accuracy: 0.5930 - mse: 4.3247e-04 - val_loss: 0.0158 - val_accuracy: 0.6163 - val_mse: 2.8269e-04\n",
      "Epoch 100/100\n",
      "104/104 [==============================] - 10s 101ms/step - loss: 0.0200 - accuracy: 0.5874 - mse: 4.4436e-04 - val_loss: 0.0172 - val_accuracy: 0.6130 - val_mse: 3.2454e-04\n",
      "Epoch 1/100\n",
      "104/104 [==============================] - 16s 121ms/step - loss: 0.1364 - accuracy: 0.0395 - mse: 0.0249 - val_loss: 0.0859 - val_accuracy: 0.0679 - val_mse: 0.0091\n",
      "Epoch 2/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0787 - accuracy: 0.1419 - mse: 0.0075 - val_loss: 0.0597 - val_accuracy: 0.1996 - val_mse: 0.0042\n",
      "Epoch 3/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0671 - accuracy: 0.1929 - mse: 0.0052 - val_loss: 0.0614 - val_accuracy: 0.2439 - val_mse: 0.0043\n",
      "Epoch 4/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0588 - accuracy: 0.2410 - mse: 0.0040 - val_loss: 0.0614 - val_accuracy: 0.2553 - val_mse: 0.0042\n",
      "Epoch 5/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0548 - accuracy: 0.2648 - mse: 0.0035 - val_loss: 0.0520 - val_accuracy: 0.2730 - val_mse: 0.0032\n",
      "Epoch 6/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0529 - accuracy: 0.2766 - mse: 0.0032 - val_loss: 0.0508 - val_accuracy: 0.2925 - val_mse: 0.0030\n",
      "Epoch 7/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0508 - accuracy: 0.2948 - mse: 0.0030 - val_loss: 0.0434 - val_accuracy: 0.3003 - val_mse: 0.0022\n",
      "Epoch 8/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0458 - accuracy: 0.3101 - mse: 0.0024 - val_loss: 0.0406 - val_accuracy: 0.3255 - val_mse: 0.0019\n",
      "Epoch 9/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0456 - accuracy: 0.3165 - mse: 0.0024 - val_loss: 0.0441 - val_accuracy: 0.3379 - val_mse: 0.0023\n",
      "Epoch 10/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0438 - accuracy: 0.3343 - mse: 0.0022 - val_loss: 0.0356 - val_accuracy: 0.3288 - val_mse: 0.0014\n",
      "Epoch 11/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0410 - accuracy: 0.3332 - mse: 0.0019 - val_loss: 0.0361 - val_accuracy: 0.3327 - val_mse: 0.0015\n",
      "Epoch 12/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0425 - accuracy: 0.3390 - mse: 0.0021 - val_loss: 0.0361 - val_accuracy: 0.3444 - val_mse: 0.0015\n",
      "Epoch 13/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0391 - accuracy: 0.3531 - mse: 0.0017 - val_loss: 0.0397 - val_accuracy: 0.3389 - val_mse: 0.0018\n",
      "Epoch 14/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0399 - accuracy: 0.3635 - mse: 0.0018 - val_loss: 0.0358 - val_accuracy: 0.3612 - val_mse: 0.0015\n",
      "Epoch 15/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0384 - accuracy: 0.3595 - mse: 0.0017 - val_loss: 0.0355 - val_accuracy: 0.3564 - val_mse: 0.0014\n",
      "Epoch 16/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0369 - accuracy: 0.3720 - mse: 0.0016 - val_loss: 0.0308 - val_accuracy: 0.3612 - val_mse: 0.0011\n",
      "Epoch 17/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0357 - accuracy: 0.3809 - mse: 0.0014 - val_loss: 0.0320 - val_accuracy: 0.4006 - val_mse: 0.0011\n",
      "Epoch 18/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0359 - accuracy: 0.3880 - mse: 0.0015 - val_loss: 0.0339 - val_accuracy: 0.3960 - val_mse: 0.0013\n",
      "Epoch 19/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0367 - accuracy: 0.3841 - mse: 0.0015 - val_loss: 0.0306 - val_accuracy: 0.4179 - val_mse: 0.0011\n",
      "Epoch 20/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0368 - accuracy: 0.3915 - mse: 0.0015 - val_loss: 0.0328 - val_accuracy: 0.3973 - val_mse: 0.0012\n",
      "Epoch 21/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0345 - accuracy: 0.3990 - mse: 0.0013 - val_loss: 0.0362 - val_accuracy: 0.4022 - val_mse: 0.0015\n",
      "Epoch 22/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0346 - accuracy: 0.4042 - mse: 0.0014 - val_loss: 0.0303 - val_accuracy: 0.4285 - val_mse: 0.0010\n",
      "Epoch 23/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0343 - accuracy: 0.4086 - mse: 0.0013 - val_loss: 0.0431 - val_accuracy: 0.3743 - val_mse: 0.0020\n",
      "Epoch 24/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0334 - accuracy: 0.4161 - mse: 0.0013 - val_loss: 0.0310 - val_accuracy: 0.4347 - val_mse: 0.0011\n",
      "Epoch 25/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0338 - accuracy: 0.4170 - mse: 0.0013 - val_loss: 0.0299 - val_accuracy: 0.4071 - val_mse: 0.0010\n",
      "Epoch 26/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0333 - accuracy: 0.4199 - mse: 0.0013 - val_loss: 0.0326 - val_accuracy: 0.3870 - val_mse: 0.0012\n",
      "Epoch 27/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0335 - accuracy: 0.4159 - mse: 0.0013 - val_loss: 0.0351 - val_accuracy: 0.4172 - val_mse: 0.0014\n",
      "Epoch 28/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0330 - accuracy: 0.4348 - mse: 0.0012 - val_loss: 0.0294 - val_accuracy: 0.4316 - val_mse: 9.7699e-04\n",
      "Epoch 29/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0326 - accuracy: 0.4234 - mse: 0.0012 - val_loss: 0.0279 - val_accuracy: 0.4456 - val_mse: 8.7403e-04\n",
      "Epoch 30/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0587 - accuracy: 0.3958 - mse: 0.0243 - val_loss: 0.0634 - val_accuracy: 0.2523 - val_mse: 0.0046\n",
      "Epoch 31/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0507 - accuracy: 0.3256 - mse: 0.0029 - val_loss: 0.0479 - val_accuracy: 0.3661 - val_mse: 0.0025\n",
      "Epoch 32/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0414 - accuracy: 0.3631 - mse: 0.0020 - val_loss: 0.0375 - val_accuracy: 0.3743 - val_mse: 0.0016\n",
      "Epoch 33/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0353 - accuracy: 0.3956 - mse: 0.0014 - val_loss: 0.0301 - val_accuracy: 0.4365 - val_mse: 0.0010\n",
      "Epoch 34/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0339 - accuracy: 0.4160 - mse: 0.0013 - val_loss: 0.0300 - val_accuracy: 0.4132 - val_mse: 0.0010\n",
      "Epoch 35/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0332 - accuracy: 0.4230 - mse: 0.0013 - val_loss: 0.0295 - val_accuracy: 0.4242 - val_mse: 9.8641e-04\n",
      "Epoch 36/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0318 - accuracy: 0.4392 - mse: 0.0011 - val_loss: 0.0291 - val_accuracy: 0.4525 - val_mse: 9.4789e-04\n",
      "Epoch 37/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0308 - accuracy: 0.4468 - mse: 0.0011 - val_loss: 0.0359 - val_accuracy: 0.4402 - val_mse: 0.0014\n",
      "Epoch 38/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0320 - accuracy: 0.4291 - mse: 0.0012 - val_loss: 0.0274 - val_accuracy: 0.4242 - val_mse: 8.4925e-04\n",
      "Epoch 39/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0305 - accuracy: 0.4511 - mse: 0.0011 - val_loss: 0.0253 - val_accuracy: 0.4685 - val_mse: 7.1311e-04\n",
      "Epoch 40/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0306 - accuracy: 0.4509 - mse: 0.0011 - val_loss: 0.0302 - val_accuracy: 0.4474 - val_mse: 0.0010\n",
      "Epoch 41/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0292 - accuracy: 0.4620 - mse: 9.6580e-04 - val_loss: 0.0252 - val_accuracy: 0.4756 - val_mse: 7.1472e-04\n",
      "Epoch 42/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0292 - accuracy: 0.4622 - mse: 9.6389e-04 - val_loss: 0.0262 - val_accuracy: 0.4593 - val_mse: 7.8084e-04\n",
      "Epoch 43/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0294 - accuracy: 0.4581 - mse: 9.7926e-04 - val_loss: 0.0289 - val_accuracy: 0.4636 - val_mse: 9.2174e-04\n",
      "Epoch 44/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0280 - accuracy: 0.4673 - mse: 8.8833e-04 - val_loss: 0.0259 - val_accuracy: 0.4772 - val_mse: 7.5464e-04\n",
      "Epoch 45/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0278 - accuracy: 0.4756 - mse: 8.7659e-04 - val_loss: 0.0285 - val_accuracy: 0.4804 - val_mse: 8.9905e-04\n",
      "Epoch 46/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0293 - accuracy: 0.4720 - mse: 9.7472e-04 - val_loss: 0.0243 - val_accuracy: 0.4972 - val_mse: 6.5962e-04\n",
      "Epoch 47/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0285 - accuracy: 0.4773 - mse: 9.2143e-04 - val_loss: 0.0247 - val_accuracy: 0.5093 - val_mse: 6.8146e-04\n",
      "Epoch 48/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0273 - accuracy: 0.4740 - mse: 8.4630e-04 - val_loss: 0.0267 - val_accuracy: 0.4879 - val_mse: 7.8333e-04\n",
      "Epoch 49/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0281 - accuracy: 0.4766 - mse: 8.8807e-04 - val_loss: 0.0239 - val_accuracy: 0.5162 - val_mse: 6.4100e-04\n",
      "Epoch 50/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0270 - accuracy: 0.4821 - mse: 8.2529e-04 - val_loss: 0.0231 - val_accuracy: 0.4999 - val_mse: 6.0389e-04\n",
      "Epoch 51/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0266 - accuracy: 0.4867 - mse: 8.0181e-04 - val_loss: 0.0243 - val_accuracy: 0.5041 - val_mse: 6.6750e-04\n",
      "Epoch 52/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0266 - accuracy: 0.4884 - mse: 8.0539e-04 - val_loss: 0.0249 - val_accuracy: 0.5012 - val_mse: 7.0304e-04\n",
      "Epoch 53/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0268 - accuracy: 0.4954 - mse: 8.1425e-04 - val_loss: 0.0243 - val_accuracy: 0.4933 - val_mse: 6.6889e-04\n",
      "Epoch 54/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0283 - accuracy: 0.4944 - mse: 8.9630e-04 - val_loss: 0.0253 - val_accuracy: 0.4834 - val_mse: 7.0324e-04\n",
      "Epoch 55/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0260 - accuracy: 0.4951 - mse: 7.6403e-04 - val_loss: 0.0221 - val_accuracy: 0.5179 - val_mse: 5.5267e-04\n",
      "Epoch 56/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0253 - accuracy: 0.5083 - mse: 7.2324e-04 - val_loss: 0.0214 - val_accuracy: 0.5143 - val_mse: 5.2566e-04\n",
      "Epoch 57/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0265 - accuracy: 0.4957 - mse: 7.9826e-04 - val_loss: 0.0255 - val_accuracy: 0.4745 - val_mse: 7.3710e-04\n",
      "Epoch 58/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0267 - accuracy: 0.5012 - mse: 8.0802e-04 - val_loss: 0.0219 - val_accuracy: 0.5200 - val_mse: 5.3929e-04\n",
      "Epoch 59/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0255 - accuracy: 0.5029 - mse: 7.3741e-04 - val_loss: 0.0225 - val_accuracy: 0.5095 - val_mse: 5.7077e-04\n",
      "Epoch 60/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0254 - accuracy: 0.5136 - mse: 7.2490e-04 - val_loss: 0.0219 - val_accuracy: 0.5369 - val_mse: 5.4827e-04\n",
      "Epoch 61/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0251 - accuracy: 0.5179 - mse: 7.1425e-04 - val_loss: 0.0220 - val_accuracy: 0.5323 - val_mse: 5.4121e-04\n",
      "Epoch 62/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0251 - accuracy: 0.5135 - mse: 7.1153e-04 - val_loss: 0.0217 - val_accuracy: 0.5400 - val_mse: 5.2854e-04\n",
      "Epoch 63/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0244 - accuracy: 0.5180 - mse: 6.7179e-04 - val_loss: 0.0220 - val_accuracy: 0.5309 - val_mse: 5.3949e-04\n",
      "Epoch 64/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0251 - accuracy: 0.5099 - mse: 7.1138e-04 - val_loss: 0.0237 - val_accuracy: 0.5331 - val_mse: 6.3355e-04\n",
      "Epoch 65/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0283 - accuracy: 0.4927 - mse: 9.2709e-04 - val_loss: 0.0413 - val_accuracy: 0.4954 - val_mse: 0.0022\n",
      "Epoch 66/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0342 - accuracy: 0.4515 - mse: 0.0014 - val_loss: 0.0244 - val_accuracy: 0.4897 - val_mse: 6.7116e-04\n",
      "Epoch 67/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0260 - accuracy: 0.5080 - mse: 7.6343e-04 - val_loss: 0.0216 - val_accuracy: 0.5275 - val_mse: 5.3649e-04\n",
      "Epoch 68/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0258 - accuracy: 0.5050 - mse: 7.5385e-04 - val_loss: 0.0207 - val_accuracy: 0.5421 - val_mse: 4.8360e-04\n",
      "Epoch 69/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0245 - accuracy: 0.5164 - mse: 6.7868e-04 - val_loss: 0.0207 - val_accuracy: 0.5361 - val_mse: 4.8724e-04\n",
      "Epoch 70/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0241 - accuracy: 0.5257 - mse: 6.5357e-04 - val_loss: 0.0210 - val_accuracy: 0.5173 - val_mse: 5.0102e-04\n",
      "Epoch 71/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0247 - accuracy: 0.5189 - mse: 6.9125e-04 - val_loss: 0.0224 - val_accuracy: 0.5533 - val_mse: 5.5706e-04\n",
      "Epoch 72/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0245 - accuracy: 0.5185 - mse: 6.7853e-04 - val_loss: 0.0199 - val_accuracy: 0.5540 - val_mse: 4.4498e-04\n",
      "Epoch 73/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0232 - accuracy: 0.5325 - mse: 6.1052e-04 - val_loss: 0.0199 - val_accuracy: 0.5441 - val_mse: 4.5075e-04\n",
      "Epoch 74/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0241 - accuracy: 0.5272 - mse: 6.5548e-04 - val_loss: 0.0210 - val_accuracy: 0.5372 - val_mse: 4.9276e-04\n",
      "Epoch 75/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0234 - accuracy: 0.5391 - mse: 6.1729e-04 - val_loss: 0.0200 - val_accuracy: 0.5417 - val_mse: 4.5166e-04\n",
      "Epoch 76/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0235 - accuracy: 0.5294 - mse: 6.2796e-04 - val_loss: 0.0205 - val_accuracy: 0.5505 - val_mse: 4.7824e-04\n",
      "Epoch 77/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0229 - accuracy: 0.5366 - mse: 5.9449e-04 - val_loss: 0.0199 - val_accuracy: 0.5656 - val_mse: 4.4769e-04\n",
      "Epoch 78/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0235 - accuracy: 0.5474 - mse: 6.2672e-04 - val_loss: 0.0204 - val_accuracy: 0.5545 - val_mse: 4.6313e-04\n",
      "Epoch 79/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0233 - accuracy: 0.5424 - mse: 6.1522e-04 - val_loss: 0.0221 - val_accuracy: 0.5281 - val_mse: 5.5300e-04\n",
      "Epoch 80/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0241 - accuracy: 0.5381 - mse: 6.5778e-04 - val_loss: 0.0196 - val_accuracy: 0.5576 - val_mse: 4.3818e-04\n",
      "Epoch 81/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0230 - accuracy: 0.5421 - mse: 5.9446e-04 - val_loss: 0.0192 - val_accuracy: 0.5670 - val_mse: 4.1754e-04\n",
      "Epoch 82/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0228 - accuracy: 0.5401 - mse: 5.8536e-04 - val_loss: 0.0186 - val_accuracy: 0.5645 - val_mse: 3.9365e-04\n",
      "Epoch 83/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0224 - accuracy: 0.5435 - mse: 5.6264e-04 - val_loss: 0.0188 - val_accuracy: 0.5624 - val_mse: 4.0254e-04\n",
      "Epoch 84/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0234 - accuracy: 0.5469 - mse: 6.2172e-04 - val_loss: 0.0211 - val_accuracy: 0.5303 - val_mse: 5.0298e-04\n",
      "Epoch 85/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0240 - accuracy: 0.5300 - mse: 6.5690e-04 - val_loss: 0.0197 - val_accuracy: 0.5776 - val_mse: 4.3634e-04\n",
      "Epoch 86/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0223 - accuracy: 0.5571 - mse: 5.6522e-04 - val_loss: 0.0187 - val_accuracy: 0.5730 - val_mse: 3.9656e-04\n",
      "Epoch 87/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0244 - accuracy: 0.5410 - mse: 6.6922e-04 - val_loss: 0.0228 - val_accuracy: 0.5343 - val_mse: 5.9315e-04\n",
      "Epoch 88/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0261 - accuracy: 0.5318 - mse: 7.8738e-04 - val_loss: 0.0200 - val_accuracy: 0.5535 - val_mse: 4.5231e-04\n",
      "Epoch 89/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0226 - accuracy: 0.5540 - mse: 5.7920e-04 - val_loss: 0.0201 - val_accuracy: 0.5549 - val_mse: 4.5887e-04\n",
      "Epoch 90/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0222 - accuracy: 0.5526 - mse: 5.5778e-04 - val_loss: 0.0185 - val_accuracy: 0.5809 - val_mse: 3.8599e-04\n",
      "Epoch 91/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0217 - accuracy: 0.5655 - mse: 5.2988e-04 - val_loss: 0.0184 - val_accuracy: 0.5857 - val_mse: 3.8463e-04\n",
      "Epoch 92/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0217 - accuracy: 0.5632 - mse: 5.2946e-04 - val_loss: 0.0186 - val_accuracy: 0.5636 - val_mse: 3.8900e-04\n",
      "Epoch 93/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0216 - accuracy: 0.5606 - mse: 5.2922e-04 - val_loss: 0.0190 - val_accuracy: 0.5586 - val_mse: 4.1002e-04\n",
      "Epoch 94/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0218 - accuracy: 0.5592 - mse: 5.3607e-04 - val_loss: 0.0182 - val_accuracy: 0.5788 - val_mse: 3.7350e-04\n",
      "Epoch 95/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0215 - accuracy: 0.5599 - mse: 5.2614e-04 - val_loss: 0.0222 - val_accuracy: 0.5324 - val_mse: 5.6377e-04\n",
      "Epoch 96/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0217 - accuracy: 0.5623 - mse: 5.3604e-04 - val_loss: 0.0183 - val_accuracy: 0.5645 - val_mse: 3.8365e-04\n",
      "Epoch 97/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0216 - accuracy: 0.5532 - mse: 5.2622e-04 - val_loss: 0.0188 - val_accuracy: 0.5819 - val_mse: 3.9608e-04\n",
      "Epoch 98/100\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0215 - accuracy: 0.5691 - mse: 5.2625e-04 - val_loss: 0.0182 - val_accuracy: 0.5729 - val_mse: 3.7526e-04\n",
      "Epoch 99/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0213 - accuracy: 0.5646 - mse: 5.1459e-04 - val_loss: 0.0183 - val_accuracy: 0.5742 - val_mse: 3.7421e-04\n",
      "Epoch 100/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0241 - accuracy: 0.5391 - mse: 6.7456e-04 - val_loss: 0.0203 - val_accuracy: 0.5497 - val_mse: 4.6328e-04\n"
     ]
    }
   ],
   "source": [
    "history_list = []\n",
    "epochs = 100\n",
    "\n",
    "i = 5\n",
    "set_name = 'set6/'\n",
    "plot_path_dir = 'metrics/' + set_name\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        history = model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=32,\n",
    "            validation_data=(x_val, y_val)\n",
    "        )\n",
    "\n",
    "        history_list.append(history)\n",
    "\n",
    "        model_name = 'LSTM' + str(i)\n",
    "        # model.save('models/' + set_name + model_name + '/model')\n",
    "\n",
    "        plot_path_loss = plot_path_dir + 'LOSS_' + model_name + '.png'\n",
    "        validation_plot(history.history['loss'], history.history['val_loss'], 'train vs validation loss', f=lambda: plt.savefig(plot_path_loss))\n",
    "\n",
    "        plot_path_mse = plot_path_dir + 'MSE_' + model_name + '.png'\n",
    "        validation_plot(history.history['mse'], history.history['val_mse'], 'train vs validation mse', f=lambda: plt.savefig(plot_path_mse), plot_type='mse')\n",
    "\n",
    "        plot_path_accuracy = plot_path_dir + 'ACCURACY_' + model_name + '.png'\n",
    "        validation_plot(history.history['accuracy'], history.history['val_accuracy'], 'train vs validation accuracy', f=lambda: plt.savefig(plot_path_accuracy), plot_type='accuracy')\n",
    "\n",
    "    except:\n",
    "\n",
    "        print('ERRO NO MODELO ' + str(i))\n",
    "    \n",
    "    \n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
