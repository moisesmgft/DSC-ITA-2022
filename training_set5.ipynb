{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if keras is using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "K._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_sets_path = 'data/tickers/sets/'\n",
    "\n",
    "sets_files = sorted([tickers_sets_path + x for x in listdir(tickers_sets_path) if 'json' in x], reverse=True)\n",
    "\n",
    "tickers_sets = []\n",
    "\n",
    "for set_file in sets_files:\n",
    "    with open(set_file, 'r') as f:\n",
    "        tickers_sets.append(json.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset.csv')\n",
    "df = df.set_index('Date')\n",
    "df = df[:-60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training sets and data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sets = [0]\n",
    "out_sets = [0]\n",
    "data_size = 4800\n",
    "\n",
    "input_tickers = set()\n",
    "output_tickers = set()\n",
    "for in_set in in_sets:\n",
    "    input_tickers = input_tickers.union(set(tickers_sets[in_set]))\n",
    "\n",
    "for out_set in out_sets:\n",
    "    output_tickers = output_tickers.union(set(tickers_sets[out_set]))\n",
    "\n",
    "input_tickers = list(input_tickers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, x, y, dic = dataa(df, data_size, input_tickers, output_tickers, \\\n",
    "                        step_size=1, input_size=60, output_size=20, \\\n",
    "                        feature_range=(0,1), return_log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset i training, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = train_val_test_split(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (x.shape[1],x.shape[2])\n",
    "output_shape = (y.shape[1], y.shape[2])\n",
    "layers_info_list = [\n",
    "    [\n",
    "        (450, 0.2, True), \n",
    "        (600, 0.2, True),\n",
    "        (600, 0.2, True),\n",
    "        (400, 0.2, False)\n",
    "    ],\n",
    "    [\n",
    "        (1000, 0.15, True), \n",
    "        (1000, 0.15, True),\n",
    "        (1000, 0.15, False)\n",
    "    ]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "hyperparameters = [0,1]\n",
    "\n",
    "for i in hyperparameters:\n",
    "    layers_info = layers_info_list[i]\n",
    "    models.append(create_model(input_shape, output_shape, layers_info, metrics=['accuracy', 'mse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_list = []\n",
    "epochs_list = [\n",
    "    150,\n",
    "    150\n",
    "]\n",
    "\n",
    "set_name = 'set6/'\n",
    "plot_path_dir = 'metrics/' + set_name\n",
    "extra_info = ''\n",
    "\n",
    "j=0\n",
    "for i in hyperparameters:\n",
    "\n",
    "    model = models[j]\n",
    "    epochs = epochs_list[j]\n",
    "    j += 1\n",
    "    try:\n",
    "        \n",
    "        history = model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=32,\n",
    "            validation_data=(x_val, y_val)\n",
    "        )\n",
    "\n",
    "        history_list.append(history)\n",
    "\n",
    "        model_name = 'LSTM' + str(i) + extra_info\n",
    "        # model.save('models/' + set_name + model_name + '/model')\n",
    "\n",
    "        plot_path_loss = plot_path_dir + 'LOSS_' + model_name + '.png'\n",
    "        validation_plot(history.history['loss'], history.history['val_loss'], 'train vs validation loss', f=lambda: plt.savefig(plot_path_loss))\n",
    "\n",
    "        plot_path_mse = plot_path_dir + 'MSE_' + model_name + '.png'\n",
    "        validation_plot(history.history['mse'], history.history['val_mse'], 'train vs validation mse', f=lambda: plt.savefig(plot_path_mse), plot_type='mse')\n",
    "\n",
    "        plot_path_accuracy = plot_path_dir + 'ACCURACY_' + model_name + '.png'\n",
    "        validation_plot(history.history['accuracy'], history.history['val_accuracy'], 'train vs validation accuracy', f=lambda: plt.savefig(plot_path_accuracy), plot_type='accuracy')\n",
    "\n",
    "    except:\n",
    "\n",
    "        print('ERRO NO MODELO ' + str(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    y_predict = model.predict(x_val)\n",
    "    mse_ = np.square(np.subtract(y_val,y_predict)).mean(axis=1)\n",
    "    var_ = np.var(np.subtract(y_val,y_predict), axis=1)\n",
    "    e_ = np.sum(np.mean(np.sqrt(np.add(mse_,var_)),axis=0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2, x2, y2, dic2 = dataa(df, data_size, input_tickers, output_tickers, \\\n",
    "                        step_size=1, input_size=60, output_size=20, \\\n",
    "                        feature_range=(0,1), return_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_train, y2_train, x2_val, y2_val, x2_test, y2_test = train_val_test_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models2 = []\n",
    "hyperparameters = [0,1]\n",
    "\n",
    "for i in hyperparameters:\n",
    "    layers_info = layers_info_list[i]\n",
    "    models2.append(create_model(input_shape, output_shape, layers_info, metrics=['accuracy', 'mse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2_list = []\n",
    "epochs_list = [\n",
    "    150,\n",
    "    150\n",
    "]\n",
    "\n",
    "set_name = 'set6/'\n",
    "plot_path_dir = 'metrics/' + set_name\n",
    "extra_info = '_RETURN_LOG'\n",
    "\n",
    "j=0\n",
    "for i in hyperparameters:\n",
    "\n",
    "    model = models2[j]\n",
    "    epochs = epochs_list[j]\n",
    "    j += 1\n",
    "    try:\n",
    "        \n",
    "        history = model.fit(\n",
    "            x=x2_train,\n",
    "            y=y2_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=32,\n",
    "            validation_data=(x2_val, y2_val)\n",
    "        )\n",
    "\n",
    "        history2_list.append(history)\n",
    "\n",
    "        model_name = 'LSTM' + str(i) + extra_info\n",
    "        # model.save('models/' + set_name + model_name + '/model')\n",
    "\n",
    "        plot_path_loss = plot_path_dir + 'LOSS_' + model_name + '.png'\n",
    "        validation_plot(history.history['loss'], history.history['val_loss'], 'train vs validation loss', f=lambda: plt.savefig(plot_path_loss))\n",
    "\n",
    "        plot_path_mse = plot_path_dir + 'MSE_' + model_name + '.png'\n",
    "        validation_plot(history.history['mse'], history.history['val_mse'], 'train vs validation mse', f=lambda: plt.savefig(plot_path_mse), plot_type='mse')\n",
    "\n",
    "        plot_path_accuracy = plot_path_dir + 'ACCURACY_' + model_name + '.png'\n",
    "        validation_plot(history.history['accuracy'], history.history['val_accuracy'], 'train vs validation accuracy', f=lambda: plt.savefig(plot_path_accuracy), plot_type='accuracy')\n",
    "\n",
    "    except:\n",
    "\n",
    "        print('ERRO NO MODELO ' + str(i))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
